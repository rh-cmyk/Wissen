#source 

# Brian Armstrong, “Ideas on How to Improve Scientific Research,” Medium, December 31, 2019, https://medium.com/@barmstrong/ideas-on-how-to-improve-scientific-research-9e2e56474132.

"Most new products that get created rely on marketing and branding to differentiate." ([Armstrong 2019:2](zotero://open-pdf/library/items/PL32VT4Q?page=2))

"Maybe we can create some translation tools to help improve the flow of ideas from academic research to business." ([Armstrong 2019:3](zotero://open-pdf/library/items/PL32VT4Q?page=3))

"Academia exists in a weird alternate reality where money and traditional market incentives don't seem to matter. Tenure, citations, and the opinion of your peers is what leads to grants, so instead this has become the currency of academia.
[...] they use alternate currencies (like citations). Perhaps licensing could be simplified to align research more with market incentives and help scientists capture more upside form their inventions." ([Armstrong 2019:3](zotero://open-pdf/library/items/PL32VT4Q?page=3))

"It would be nice if research happened more like open source software and was more aligned with market incentives. It would also be nice if there was prioritization like Reddit, comments like Google Docs, and pull requests like GitHub." ([Armstrong 2019:4](zotero://open-pdf/library/items/PL32VT4Q?page=4))

"we need to replicate the positive aspects of journals (curation of content and status/reputation for those getting published) and eliminate the negative aspects (cost and delays)." ([Armstrong 2019:5](zotero://open-pdf/library/items/PL32VT4Q?page=5))

"If we can get trusted people to rate papers, we can turn this into rankings or leaderboards. Imagine being able to see the "top papers in biology this year/month/week" based on crowd sourced votes from knowledgeable people.

I could imagine research being rated across a handful of metrics:

1. Originality
Is there a genuine breakthrough here that added a branch on the tree of knowledge?

2. Reproducibility
Does the paper contain sufficient detail for others to reproduce the work, and how many other people/labs have actually been able to do so?

3. Commercial viability
Could this research plausibly lead to something that would benefit people? These ratings could be aggregated into an overall score for each paper, possibly eventually incorporating hundreds of variables (like Page Rank)." ([Armstrong 2019:5](zotero://open-pdf/library/items/PL32VT4Q?page=5))

"Users who want to remain anonymous may not be able to bring their external reputation with them to the site (this is downside), but hopefully they can speak freely and "crazy" ideas can be evaluated on their own merit." ([Armstrong 2019:6](zotero://open-pdf/library/items/PL32VT4Q?page=6))

"One idea on this is to do an ICO of sorts, and give away a coin that incentivises the behavior the community needs to keep growing. People could potentially also apply for grants and get paid in this new coin." ([Armstrong 2019:6](zotero://open-pdf/library/items/PL32VT4Q?page=6))

"Imagine having a "License" button at the bottom of every research paper profile page that hand holds you through the process. Or imagine having standard licensing terms, similar to the YCombinator SAFE documents, but for licensing the technology. Ideally, people could license your technology in 5 minutes, without ever having the pick up the phone. Every piece of research published could be available under one of the following licenses (for instance):

1. Free, public domain
This could actually be a requirement depending on the source of funding.

2. "Standard" license terms
For instance, receive 1-5% of profit for any product derived from it for the first 5 years. Non-exclusive license.

3. Custom
Contact the tech transfer office (or equivalent) to discuss a custom deal." ([Armstrong 2019:7](zotero://open-pdf/library/items/PL32VT4Q?page=7))

"it would be great to see a "plain English" explanation of what each paper attempted to do, and what it found. These summaries could be crowdsourced like Wikipedia or written by paying grad students, for instance." ([Armstrong 2019:7](zotero://open-pdf/library/items/PL32VT4Q?page=7))

"Speaking in code helps ensure that only the people they want to speak with can understand what they're saying. This is a reasonable survival instinct, but it also means that most research is happening in small closed groups." ([Armstrong 2019:8](zotero://open-pdf/library/items/PL32VT4Q?page=8))

"how powerful nested and voted/sorted comments are. [...] They are not terribly difficult to implement, yet the vast majority of sites on the internet still have comment section that are chronological and filled with low quality content. [...] It would also be interesting to try inline comments like on Genius.com or Google Docs to discuss specific lines in papers. [...] Why not allow people to submit pull requests to papers like on Github, or make suggested edits like in Google Docs? Why not let people add collaborators (even if they've never met in real life). Why not let people fork research and take it in a new direction?" ([Armstrong 2019:9](zotero://open-pdf/library/items/PL32VT4Q?page=9))

"It would be great if people could post in progress research as well. Maybe just a hypothesis (something you'd like to see tested in the future), or a dataset (that you weren't able to draw any conclusions from, but maybe someone else could). This could also take the form of a Jupyter notebook." ([Armstrong 2019:9](zotero://open-pdf/library/items/PL32VT4Q?page=9))

"Maybe the more fundamental unit is really an experiment. What did you try? What was the result? What does this imply? How sure are we that it is true/correct? What are some examples where this could be useful?" ([Armstrong 2019:10](zotero://open-pdf/library/items/PL32VT4Q?page=10))

"Arxiv-sanity
Great step in the right direction to make the overwhelming number of papers which are published a bit more accessible, but could go even further. For instance, it only covers machine learning papers." ([Armstrong 2019:10](zotero://open-pdf/library/items/PL32VT4Q?page=10))